{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6384ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values by mean imputation...\n",
      "Missing values handled.\n",
      "\n",
      "## Determining Most Important Features (using RandomForest):\n",
      "            feature  importance\n",
      "10            sysBP    0.130597\n",
      "12              BMI    0.127503\n",
      "1               age    0.126334\n",
      "9           totChol    0.123492\n",
      "14          glucose    0.118363\n",
      "11            diaBP    0.110702\n",
      "13        heartRate    0.095294\n",
      "4        cigsPerDay    0.050460\n",
      "2         education    0.041157\n",
      "0              male    0.018898\n",
      "7      prevalentHyp    0.018123\n",
      "3     currentSmoker    0.012965\n",
      "5            BPMeds    0.011895\n",
      "8          diabetes    0.008236\n",
      "6   prevalentStroke    0.005980\n",
      "\n",
      "============================================================\n",
      "\n",
      "## Logistic Regression without SMOTE:\n",
      "Accuracy: 0.8443\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       719\n",
      "           1       0.41      0.05      0.10       129\n",
      "\n",
      "    accuracy                           0.84       848\n",
      "   macro avg       0.63      0.52      0.51       848\n",
      "weighted avg       0.79      0.84      0.79       848\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "## Ensemble (Logistic Regression + KNN) without SMOTE:\n",
      "Accuracy: 0.8502\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       719\n",
      "           1       0.67      0.03      0.06       129\n",
      "\n",
      "    accuracy                           0.85       848\n",
      "   macro avg       0.76      0.51      0.49       848\n",
      "weighted avg       0.82      0.85      0.79       848\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Class distribution in original training data:\n",
      "TenYearCHD\n",
      "0    2877\n",
      "1     515\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in SMOTE training data:\n",
      "TenYearCHD\n",
      "0    2877\n",
      "1    2877\n",
      "Name: count, dtype: int64\n",
      "Shape of training data before SMOTE: (3392, 15)\n",
      "Shape of training data after SMOTE: (5754, 15)\n",
      "\n",
      "============================================================\n",
      "\n",
      "## Logistic Regression with SMOTE:\n",
      "Accuracy: 0.6698\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       719\n",
      "           1       0.26      0.61      0.36       129\n",
      "\n",
      "    accuracy                           0.67       848\n",
      "   macro avg       0.58      0.65      0.57       848\n",
      "weighted avg       0.81      0.67      0.71       848\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "## Ensemble (Logistic Regression + KNN) with SMOTE:\n",
      "Accuracy: 0.7547\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       719\n",
      "           1       0.27      0.36      0.31       129\n",
      "\n",
      "    accuracy                           0.75       848\n",
      "   macro avg       0.58      0.59      0.58       848\n",
      "weighted avg       0.79      0.75      0.77       848\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "SMOTE-augmented training dataset saved to 'framingham_extended.csv'\n",
      "Shape of the extended dataset: (5754, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('framingham.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'framingham.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Handling missing values by mean imputation...\")\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().any():\n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "print(\"Missing values handled.\\n\")\n",
    "\n",
    "X = df.drop('TenYearCHD', axis=1)\n",
    "y = df['TenYearCHD']\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "print(\"## Determining Most Important Features (using RandomForest):\")\n",
    "rf_model_fi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_fi.fit(X_train_scaled_df, y_train)\n",
    "importances = rf_model_fi.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "print(feature_importance_df)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"## Logistic Regression without SMOTE:\")\n",
    "log_reg_no_smote = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "log_reg_no_smote.fit(X_train_scaled_df, y_train)\n",
    "y_pred_lr_no_smote = log_reg_no_smote.predict(X_test_scaled_df)\n",
    "accuracy_lr_no_smote = accuracy_score(y_test, y_pred_lr_no_smote)\n",
    "print(f\"Accuracy: {accuracy_lr_no_smote:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr_no_smote, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"## Ensemble (Logistic Regression + KNN) without SMOTE:\")\n",
    "knn_no_smote = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_no_smote.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "ensemble_clf_no_smote = VotingClassifier(\n",
    "    estimators=[('lr', log_reg_no_smote), ('knn', knn_no_smote)],\n",
    "    voting='hard'\n",
    ")\n",
    "ensemble_clf_no_smote.fit(X_train_scaled_df, y_train)\n",
    "y_pred_ensemble_no_smote = ensemble_clf_no_smote.predict(X_test_scaled_df)\n",
    "accuracy_ensemble_no_smote = accuracy_score(y_test, y_pred_ensemble_no_smote)\n",
    "print(f\"Accuracy: {accuracy_ensemble_no_smote:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble_no_smote, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"Class distribution in original training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "print(\"\\nClass distribution in SMOTE training data:\")\n",
    "print(y_train_smote.value_counts())\n",
    "print(f\"Shape of training data before SMOTE: {X_train_scaled_df.shape}\")\n",
    "print(f\"Shape of training data after SMOTE: {X_train_smote.shape}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"## Logistic Regression with SMOTE:\")\n",
    "log_reg_smote = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "log_reg_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_lr_smote = log_reg_smote.predict(X_test_scaled_df)\n",
    "accuracy_lr_smote = accuracy_score(y_test, y_pred_lr_smote)\n",
    "print(f\"Accuracy: {accuracy_lr_smote:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr_smote, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"## Ensemble (Logistic Regression + KNN) with SMOTE:\")\n",
    "knn_smote = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# log_reg_smote is already trained\n",
    "ensemble_clf_smote = VotingClassifier(\n",
    "    estimators=[('lr', log_reg_smote), ('knn', knn_smote)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "ensemble_clf_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_ensemble_smote = ensemble_clf_smote.predict(X_test_scaled_df)\n",
    "accuracy_ensemble_smote = accuracy_score(y_test, y_pred_ensemble_smote)\n",
    "print(f\"Accuracy: {accuracy_ensemble_smote:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble_smote, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "X_train_smote_df_save = pd.DataFrame(X_train_smote, columns=feature_names)\n",
    "y_train_smote_series_save = pd.Series(y_train_smote, name='TenYearCHD')\n",
    "framingham_extended_df = pd.concat([X_train_smote_df_save, y_train_smote_series_save], axis=1)\n",
    "try:\n",
    "    framingham_extended_df.to_csv('framingham_extended.csv', index=False)\n",
    "    print(f\"SMOTE-augmented training dataset saved to 'framingham_extended.csv'\")\n",
    "    print(f\"Shape of the extended dataset: {framingham_extended_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving 'framingham_extended.csv': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134dae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
